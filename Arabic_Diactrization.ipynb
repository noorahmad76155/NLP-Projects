{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arabic Diactrization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhj36kZ-PVn8",
        "outputId": "e09408fb-57d5-4f9f-b1a1-bdc93f3cb8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/Barqawiz/Shakkala\n",
        "%cd Shakkala/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Shakkala'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 554 (delta 10), reused 13 (delta 4), pack-reused 527\u001b[K\n",
            "Receiving objects: 100% (554/554), 312.19 MiB | 33.88 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n",
            "/content/Shakkala\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASiIx8dGQoiz",
        "outputId": "eada3506-21d6-44d9-8efb-7cddcdb7b9ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from Shakkala import Shakkala"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xkHm_lgkutS"
      },
      "source": [
        "# create Shakkala object\n",
        "sh = Shakkala('./', version=3)\n",
        "\n",
        "#load the model \n",
        "model, graph = sh.get_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WSGUB4BQvsT",
        "outputId": "5c17f4cf-7be3-4e67-faf6-badccd63548f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_text = \"\"\" ليس منا من لم يوقر كبيرنا ويعطف على صغيرنا\t\t\t\n",
        " \"\"\"\n",
        "\n",
        "# prepare input\n",
        "input_int = sh.prepare_input(input_text)\n",
        "\n",
        "# run the model\n",
        "with graph.as_default():\n",
        "    logits = model.predict(input_int)[0]\n",
        "\n",
        "# get the logits \n",
        "predicted_harakat = sh.logits_to_text(logits)\n",
        "\n",
        "# final output \n",
        "final_output = sh.get_final_text(input_text, predicted_harakat)\n",
        "\n",
        "print(final_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " لَيْسَ مِنَّا مَنْ لَمْ يُوقِرْ كَبِيرِنَا وَيُعْطَفُ عَلَى صَغِيرِنَا\tِ\tَ\tَ\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}